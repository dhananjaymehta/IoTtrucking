{"nbformat_minor": 1, "cells": [{"source": "### Step 1: Insert a project token and run the inserted code cell\n<br/>A project token will allow you to access all the resources defined within this project.  By default, the token is inserted into the very first cell in a notebook.\n<br/><img style=\"float: left;\" src=\"https://github.com/yfphoon/dsx_local/blob/master/images/project_token.png?raw=true\" alt=\"Project Token\" />", "cell_type": "markdown", "metadata": {}}, {"source": "<h1 id=\"tocheading\">Attrition Demo</h1>\n<div id=\"toc\"></div>\n\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/header.png\" width=\"800\" height=\"500\" align=\"middle\"/>", "cell_type": "markdown", "metadata": {}}, {"source": "The Attrition demo focuses on retaining Merchants that are using company network for credit card processing. Here is the description of the case:\n\nA client approved many low value merchant accounts without much scrutiny.  Many of those merchant accounts resulted in default. The client thinks that they should have put more of an emphasis on their applicant screening process. IBM suggests to enable fact based decision making for performance of its joint marketing programs.\n\nThis notebook will demostrate how to\n\n1. Use Brunel and Seaborn library for visualizations\n\n2. Use regular python Machine Learning libary scikit-learn and Spark's Machine Learning library(MLlib) for predicitive modeling in an intergrated environment on DSX.\n3. Deploy SparkML model using Machine Learning Service", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "%%javascript\n$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Load Libraries", "cell_type": "markdown", "metadata": {}}, {"source": "Run the following cell to import required libraries.", "cell_type": "markdown", "metadata": {}}, {"source": "import sklearn\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nimport pandas as pd\npd.options.display.max_columns = 999\n\nimport brunel\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom scipy.stats import chi2_contingency,ttest_ind\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nfrom sklearn.cross_validation import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n\nimport numpy as np\n\nimport urllib3, requests, json", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Load Customer History Data", "cell_type": "markdown", "metadata": {}}, {"source": "To load data into DSX environment using Object Storage, you need to:\n\n1. Download the customer history data(CUST_HISTORY.csv) <a href=\"https://github.com/elenalowery/DSX-Local-Credit-Card-Default/tree/master/data\">here</a>.\n2. Upload it into Object Storage by clicking the \"1001\" icon on the top right side -> Files -> Drag and drop or browse to select and upload the file.\n", "cell_type": "markdown", "metadata": {}}, {"source": "# \n# Access 'CUST_HISTORY.csv' data file from the project.\ncust_spark = ProjectUtil.load_dataframe_from_file(pc, \"CUST_HISTORY.csv\")\ncust_spark.show()\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "Create a Pandas DataFrame from the Spark DataFrame.  A Pandas DataFrame is required for the analysis below", "cell_type": "markdown", "metadata": {}}, {"source": "cust_pd=cust_spark.toPandas()\ncust_pd.head()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Dataset Overview", "cell_type": "markdown", "metadata": {}}, {"source": "Let's take a quick look at the dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "print \"There are \" + str(len(cust_pd)) + \" observations in the customer history dataset.\"\nprint \"There are \" + str(len(cust_pd.columns)) + \" variables in the dataset.\"\n\nprint \"\\n******************Descriptive statistics*****************************\\n\"\nprint cust_pd.describe()\n\nprint \"\\n******************Dataset Quick View*****************************\\n\"\ncust_pd.head()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "## Exploratory Data Analysis\n\nIn this section, we will explore the dataset further with some visualizations.\n\nTwo open source libraries are used:\n* <a href=\"https://github.com/Brunel-Visualization/Brunel\">Brunel</a> is a high-level language that describes visualizations in terms of composable actions. It drives a visualization engine (D3) that performs the actual rendering and interactivity. Brunel makes it much easier to build fun and inventive visualizations in Jupyter notebooks.\n\n* <a href=\"https://seaborn.pydata.org/\">Seaborn</a> is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "### Outcome Variable: Account Default", "cell_type": "markdown", "metadata": {}}, {"source": "%brunel data('cust_pd') x(IS_DEFAULT) y(#count) color(IS_DEFAULT) bar tooltip(#all)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "As you can see from the bar chart, 300 out of 1000 accounts are in default.", "cell_type": "markdown", "metadata": {}}, {"source": "### Default by Credit Program", "cell_type": "markdown", "metadata": {}}, {"source": "%brunel data('cust_pd') polar stack bar y(#count) color(CREDIT_PROGRAM) percent(#count) tooltip(#all) | stack bar x(CREDIT_PROGRAM) y(#count) color(IS_DEFAULT) bin(CREDIT_PROGRAM) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "* Top 3 credit programs with most Merchants are Electronics(28%), New Car(23.4%) and Furniture(18.1%).\n* Top 3 credit programs with high default rate are Education(44%), New Car(38%), and Retraining(35.1%)", "cell_type": "markdown", "metadata": {}}, {"source": "### Default by IS_XBORDER", "cell_type": "markdown", "metadata": {}}, {"source": "%brunel data('cust_pd') polar stack bar y(#count) color(IS_XBORDER) percent(#count) tooltip(#all) | stack bar x(IS_XBORDER) y(#count) color(IS_DEFAULT) bin(IS_XBORDER) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "Most Merchants have cross-border transactions. Relatively, they have a lower default rate than those don't have coross-border transactions.", "cell_type": "markdown", "metadata": {}}, {"source": "### RENT vs. IS_DEFAULT", "cell_type": "markdown", "metadata": {}}, {"source": "%brunel data('cust_pd') stack bar x(RENT) y(#count) color(IS_DEFAULT: blue-red) bin(RENT) sort(RENT) percent(#count) label(#count) tooltip(#all)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "From this stacked bar chart, we can see that Merchants who rent their residence have higher default rate.", "cell_type": "markdown", "metadata": {}}, {"source": "### HISTORY vs. IS_DEFAULT", "cell_type": "markdown", "metadata": {}}, {"source": "%brunel data('cust_pd') bar x(HISTORY) y(#count) color(HISTORY) tooltip(#all) | stack bar x(HISTORY) y(#count) color(IS_DEFAULT: green-red) bin(HISTORY) sort(HISTORY) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "### AMOUNT_K_USD vs. IS_DEFAULT", "cell_type": "markdown", "metadata": {}}, {"source": "sub_yes = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"Yes\"]\nsub_no = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"No\"]\n    \np_value = ttest_ind(sub_yes['AMOUNT_K_USD'], sub_no[\"AMOUNT_K_USD\"], equal_var = False)[1]\n\nfig, axs = plt.subplots(nrows= 1, figsize=(13, 5))\nsns.boxplot(x = \"IS_DEFAULT\", y = \"AMOUNT_K_USD\", data = cust_pd, showfliers=False, palette=\"Set2\")\nif p_value < .05:\n    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n The distributions for the two groups are significantly different!\" + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_no[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))\nelse:\n    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_safe[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))           ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "In this box plot, the visualization is enhanced by T-test statistics. The result is significant which indicates that the average credit amount for the non-default group and default group are different. Default group has larger average credit amount.\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "### Default rate by state", "cell_type": "markdown", "metadata": {}}, {"source": "default_rate = pd.crosstab(cust_pd.IS_DEFAULT, cust_pd.STATE).apply(lambda r: r/r.sum(), axis=0)\n\ndefault_rate2 = default_rate.T\n\n%brunel data('default_rate2') map color(Yes) key(STATE) label(STATE)\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "Brunel also provides a very neat way for map visualization. So for this use case, all the Merchants come from 4 states: NY, NJ, PA and CT.", "cell_type": "markdown", "metadata": {}}, {"source": "### Correlation Matrix\n\nA heatmap is used to visualize the correlations between all continuous variables.", "cell_type": "markdown", "metadata": {}}, {"source": "plt.figure(figsize=(12, 8))\n\ncorr_df = cust_pd.iloc[:,1:].corr()\n\nsns.heatmap(corr_df, \n            xticklabels = corr_df.columns.values,\n            yticklabels = corr_df.columns.values,\n            annot = True);\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "* There is no strong correlation between most variables.\n* The correlation between AMOUNT_K_USD and CONTRACT_DURATION_MONTH is moderate.", "cell_type": "markdown", "metadata": {}}, {"source": "## Modeling And Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "For demo purpose, we will use RandomForestClassifier() from sklearn to rank feature importance, and Logistic Regression from Spark's Machine Learning Library(MLlib) for modeling.", "cell_type": "markdown", "metadata": {}}, {"source": "### Sklearn Random Forest: Rank Feature Importance", "cell_type": "markdown", "metadata": {}}, {"source": "# convert IS_DEFAULT to 1/0\nle = LabelEncoder()\n\ncust_pd.loc[:,'IS_DEFAULT']= le.fit_transform(cust_pd.loc[:,'IS_DEFAULT'])\n\ny = np.float32(cust_pd.IS_DEFAULT)\nX = cust_pd.copy()\n\n# drop y \nX = cust_pd.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1)\n\n# Prepocess the data: Encode categorical variables into numeric representations\n\ncategoricalColumns = [\"ACCT_STATUS_K_USD\", \"BRANCHES\",'HISTORY', 'CREDIT_PROGRAM', 'ACCOUNT_TYPE', 'ACCT_AGE', 'STATE', 'IS_URBAN', 'IS_XBORDER','SELF_REPORTED_ASMT', 'CO_APPLICANT', 'GUARANTOR','PRESENT_RESIDENT', 'OWN_REAL_ESTATE', 'PROP_UNKN','OTHER_INSTALL_PLAN', 'RENT', 'OWN_RESIDENCE','TELEPHONE', 'SHIP_INTERNATIONAL']\n\nfor col in categoricalColumns:\n    X[col] = le.fit_transform(X[col])\n\n# scale X\nmin_max_scaler = MinMaxScaler()\nX = min_max_scaler.fit_transform(X)\n\n# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nrandom_forest = RandomForestClassifier()\n\n#Stratify split and train on 5 folds\nskf = StratifiedKFold(y_train, n_folds=5)\ncounter = 1\nfor train_fold, test_fold in skf:\n    random_forest.fit(X_train[train_fold], y_train[train_fold])\n    \n    print( str(counter) + \": \", random_forest.score(X_train[test_fold], y_train[test_fold]))\n    counter += 1 \n    \n#### local notes: one interesting error here, if you don't do the import correctly, it will show error Params must be either a param map or a list/tuple of param maps, but got <class 'pandas.core.series.Series'>.", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "From the result of 5-fold CV, the average accuracy varies. The model is not very stable, one possible reason is that our sample size is really small. We will need to restrict the model complexity. We will choose top 10 important features for further analysis.", "cell_type": "markdown", "metadata": {}}, {"source": "features_order = cust_pd.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1).columns.tolist()\n\nfeature_importance_dict = {key: val for key, val in zip(features_order, random_forest.feature_importances_)}\n\nfor k in sorted(feature_importance_dict, key=feature_importance_dict.get, reverse=True):\n    print k, feature_importance_dict[k]", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Default Prediction: Spark MLlib Logistic Regression", "cell_type": "markdown", "metadata": {}}, {"source": "In this section, We will use Logistic Regression from Spark MLlib to predict defalut.<br/>\nWe will use the Spark DataFrame for building the Spark ML model", "cell_type": "markdown", "metadata": {}}, {"source": "cust_spark.printSchema()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Preprocess the data**", "cell_type": "markdown", "metadata": {}}, {"source": "# group top 10 features to categorical and numerical\nallCols = cust_pd.drop(['MERCHANT','IS_DEFAULT'], 1).columns.tolist()\nimportantCols = ['AMOUNT_K_USD', 'ACCT_STATUS_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH', 'HISTORY', 'CREDIT_PROGRAM', 'ACCT_AGE', 'ACCOUNT_TYPE', \"PRESENT_RESIDENT\", \"STATE\"]\nimportantCols_num = ['AMOUNT_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH']\nimportantCols_cat = np.setdiff1d(importantCols, importantCols_num).tolist()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# create label_str column\ncust_spark = cust_spark.withColumnRenamed(\"IS_DEFAULT\", 'label_str')", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# One-hot encoder for all categorical varaibles\nfor categoricalCol in importantCols_cat:\n    cust_spark = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\").fit(cust_spark).transform(cust_spark)\n    cust_spark = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\").transform(cust_spark)  ", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Assemble feature vector\nassemblerInputs = map(lambda c: c + \"classVec\", importantCols_cat) + importantCols_num\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\ncust_spark = assembler.transform(cust_spark)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Transform the label_str column to a numeric value\ncust_spark = StringIndexer(inputCol='label_str', outputCol='label').fit(cust_spark).transform(cust_spark)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# keep useful variables\nselectedcols = [\"label\", \"features\"]\ncust_model = cust_spark.select(selectedcols)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "** Split the data into training and testing sets **", "cell_type": "markdown", "metadata": {}}, {"source": "trainingData, testData = cust_model.randomSplit([0.7, 0.3], seed = 824)\nprint trainingData.count()\nprint testData.count()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "**Train Logistic Regression Model**", "cell_type": "markdown", "metadata": {}}, {"source": "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "** Use CrossValidator and ParamGridBuilder to search for best model **", "cell_type": "markdown", "metadata": {}}, {"source": "paramGrid = ParamGridBuilder()\\\n    .addGrid(lr.regParam, [1.0,0.3,0.1, 0.03,0.01,0.0]) \\\n    .addGrid(lr.fitIntercept, [False, True])\\\n    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n    .build()\n\nevaluator = BinaryClassificationEvaluator()\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\ncvModel = cv.fit(trainingData)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "** Use BinaryClassificationEvaluator to evaluate the model**\n\nNote that the default metric for the BinaryClassificationEvaluator is *areaUnderROC*\n\nA rough guide for classifying the accuracy of a test:\n\n    .90-1 = excellent (A)\n    .80-.90 = good (B)\n    .70-.80 = fair (C)\n    .60-.70 = poor (D)\n    .50-.60 = fail (F)\n\nSo the model performance is fair.", "cell_type": "markdown", "metadata": {}}, {"source": "evaluator.evaluate(cvModel.transform(testData))", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "** Final Model**", "cell_type": "markdown", "metadata": {}}, {"source": "We will move forward with the model with Top 10 features.", "cell_type": "markdown", "metadata": {}}, {"source": "**Hyperparameters used in final model**", "cell_type": "markdown", "metadata": {}}, {"source": "print cvModel.bestModel._java_obj.getRegParam()\nprint cvModel.bestModel._java_obj.getMaxIter()\nprint cvModel.bestModel._java_obj.getElasticNetParam()\nprint cvModel.bestModel._java_obj.getThreshold()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "** Intercept and Weights **", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "print \"Model Intercept = \" + str(cvModel.bestModel.intercept)\n\ncoefficients = cvModel.bestModel.coefficients\ncoefficients = map(lambda w: (float(w),), coefficients)\nweightsDF = sqlContext.createDataFrame(coefficients, [\"Feature Weight\"])\nweightsDF.show()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Create Pipeline for ML", "cell_type": "markdown", "metadata": {}}, {"source": "cust_spark1 = sqlContext.createDataFrame(cust_pd).withColumnRenamed(\"IS_DEFAULT\", 'label')\n\ntrainingData3, testData3 = cust_spark1.randomSplit([0.7, 0.3], seed = 824)\n\nSI1 = StringIndexer(inputCol='ACCOUNT_TYPE', outputCol='ACCOUNT_TYPE'+\"Index\")\nSI2 = StringIndexer(inputCol='ACCT_AGE', outputCol='ACCT_AGE'+\"Index\")\nSI3 = StringIndexer(inputCol='ACCT_STATUS_K_USD', outputCol='ACCT_STATUS_K_USD'+\"Index\")\nSI4 = StringIndexer(inputCol='CREDIT_PROGRAM', outputCol='CREDIT_PROGRAM'+\"Index\")\nSI5 = StringIndexer(inputCol='HISTORY', outputCol='HISTORY'+\"Index\")\nSI6 = StringIndexer(inputCol='PRESENT_RESIDENT', outputCol='PRESENT_RESIDENT'+\"Index\")\nSI7 = StringIndexer(inputCol='STATE', outputCol='STATE'+\"Index\")\n\n\nOH1 = OneHotEncoder(inputCol='ACCOUNT_TYPE'+\"Index\", outputCol='ACCOUNT_TYPE'+\"classVec\")\nOH2 = OneHotEncoder(inputCol='ACCT_AGE'+\"Index\", outputCol='ACCT_AGE'+\"classVec\")\nOH3 = OneHotEncoder(inputCol='ACCT_STATUS_K_USD'+\"Index\", outputCol='ACCT_STATUS_K_USD'+\"classVec\")\nOH4 = OneHotEncoder(inputCol='CREDIT_PROGRAM'+\"Index\", outputCol='CREDIT_PROGRAM'+\"classVec\")\nOH5 = OneHotEncoder(inputCol='HISTORY'+\"Index\", outputCol='HISTORY'+\"classVec\")\nOH6 = OneHotEncoder(inputCol='PRESENT_RESIDENT'+\"Index\", outputCol='PRESENT_RESIDENT'+\"classVec\")\nOH7 = OneHotEncoder(inputCol='STATE'+\"Index\", outputCol='STATE'+\"classVec\")\n\nassembler_features = VectorAssembler(inputCols=['ACCOUNT_TYPEclassVec','ACCT_AGEclassVec','ACCT_STATUS_K_USDclassVec','CREDIT_PROGRAMclassVec','HISTORYclassVec','PRESENT_RESIDENTclassVec', 'STATEclassVec',\n 'AMOUNT_K_USD',\n 'CONTRACT_DURATION_MONTH',\n 'ESTABLISHED_MONTH'], outputCol=\"features\")\n\nlr_final = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.0, threshold = 0.5, labelCol=\"label\", featuresCol=\"features\")\n\npipeline_lr = Pipeline(stages=[SI1, SI2, SI3,SI4,SI5,SI6,SI7, OH1,OH2,OH3,OH4,OH5,OH6,OH7, assembler_features, lr_final])\nmodel_lr = pipeline_lr.fit(trainingData3)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Save Model in ML repository\n", "cell_type": "markdown", "metadata": {}}, {"source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact\n\nservice_path = 'https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443'\nml_repository_client = MLRepositoryClient()\n\nmodel_artifact = MLRepositoryArtifact(model_lr, training_data=trainingData3, name=\"Predict_CC_Default\")\n\nsaved_model = ml_repository_client.models.save(model_artifact)\n\n# Print the saved model properties\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Deploy model via UI\n\n1. Save the notebook and switch to the **Analytic Assets** tab of the project (hint: open project with another tab in your browser). \n2. Under **Models**, find and click into your deployed model. Add an **Online deployment**. \n", "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": "###  Test model with a REST API call ", "cell_type": "markdown", "metadata": {}}, {"source": "This step is to demonstrate the you can make an external REST API call to test the model\n\n* In the Deployment Details, copy the **scoring endpoint (remote access)** into your notepad, e.g. \nhttps://169.47.153.213/v2/scoring/online/dc0a0dce-f9af-4140-84af-b1eb7d92f0d5  (where 169.47.153.213 represents the master node IP)", "cell_type": "markdown", "metadata": {}}, {"source": "* Retreive the __bearer token__ for accessing your deployed model with this command: <br/>\n`!curl -k -X GET https://<master node IP>/v2/identity/token -H \"username: joe\" -H \"password: joePassword\"`", "cell_type": "markdown", "metadata": {}}, {"source": "# insert your code here\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "* copy the generated accessToken into your notepad\n\n* Create and execute this command to invoke the model remotely:\n<br/>\n<br/>\n`!curl -i -k -X POST <Scoring Endpoint> -d '{\"fields\": [\"MERCHANT\",\"ACCT_STATUS_K_USD\",\"CONTRACT_DURATION_MONTH\",\"HISTORY\",\"CREDIT_PROGRAM\",\"AMOUNT_K_USD\",\"ACCOUNT_TYPE\",\"ACCT_AGE\",\"STATE\",\"IS_URBAN\",\"IS_XBORDER\",\"SELF_REPORTED_ASMT\",\"CO_APPLICANT\",\"GUARANTOR\",\"PRESENT_RESIDENT\",\"OWN_REAL_ESTATE\",\"PROP_UNKN\",\"ESTABLISHED_MONTH\",\"OTHER_INSTALL_PLAN\",\"RENT\",\"OWN_RESIDENCE\",\"NUMBER_CREDITS\",\"RFM_SCORE\",\"BRANCHES\",\"TELEPHONE\",\"SHIP_INTERNATIONAL\"], \"records\": [[999,\"0 USD\",12,\"CRITICAL ACCOUNT\",\"NEW CAR\",2171,\"up to 100 K USD\",\"1 to 4 YRS\",\"NY\",\"NO\",\"YES\",\"NO\",\"NO\",\"NO\",\"4\",\"NO\",\"NO\",38,\"YES\",\"NO\",\"YES\",2,2,1,\"NO\",\"YES\",\"No\"]]}' -H \"content-type: application/json\" -H \"authorization: Bearer <generate bearer token>\"`", "cell_type": "markdown", "metadata": {}}, {"source": "#insert your code here\n\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Summary", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "You have finished working on this hands-on lab. In this notebook you have:\n1. Use Brunel and Seaborn library for visualizations\n\n2. Use regular python Machine Learning libary scikit-learn to build a RandomForestClassifier, and extracted the top 10 most important predictors\n3. Use Spark's Machine Learning library(MLlib) to build a LogisticRegression model with the top 10 most important predictors.\n4. Deploy SparkML model using Machine Learning Service\n", "cell_type": "markdown", "metadata": {}}, {"source": "Created by **Catherine Cao** and **Sidney Phoon**\n<br/>\ncatherine.cao@ibm.com<br/>\nyfphoon@us.ibm.com<br/>\n\nAug 30, 2017", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python2 with DSX Spark", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.13", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}